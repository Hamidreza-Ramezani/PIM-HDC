# Hyperdimensional Computing

## HDC Terms

* Hypervectors:

  By virtue of the large size of brain’s circuits, we can model neural activity patterns in points of a highdimensional space, that is, with hypervectors. When dimensionality is in the thousands (e.g., 10,000-D), the term “hyperdimensional” is used.

  Holographic and (pseudo)random with independent and identically distributed (i.i.d.) components.

  Such hypervectors can be mathematically manipulated to not only classify but also to make associations, form hierarchies, and perform other types of cognitive computations

### MAP

HD computing uses three operations: Multiplication, addition, and permutation (MAP).

MAP operations produce a D-bit hypervector.

Multiplication and permutation are invertible

* Addition:

  The addition of binary hypervectors [A + B + . . .] is defined as the
  componentwise majority with ties broken at random.

  Addition produces a hypervector that is similar to the input hypervectors

  Addition is well suited for representing sets

* Multiplication:

  The multiplication is defined as the componentwise XOR (⊕)

  Multiplication produces a dissimilar hypervector. Hence, the a, and the
  multiplication is useful for binding two hypervectors.

* Permutation:

  Permutation (ρ) shuffles the components, e.g., 1-bit rotation.

  The permutation also generates a dissimilar pseudoorthogonal hypervector that
  is good for storing a sequence.

### Main modules for Classification

* Item memory (IM)

  Maps all symbols in the system to the HD space.

  In a typical biosignal processing system, the names of channels (or electrodes)
  are the basic symbols for mapping. The IM assigns a random hypervectors
  (with i.i.d. components) to every channel’s name, i.e., E1 ⊥ E2... ⊥ Ei.

* Continuous item memory (CIM)

  Besides the discrete symbols, the system has analog values (e.g., the signal levels of channels) for mapping.
  To map these analog values, the notion of IM is further extended to a continuous item memory (CIM).

  In the continuous vector space of CIM, orthogonal endpoint hypervectors are generated for the minimum and maximum signal levels.

  The hypervectors for intermediate levels are then generated by linear interpolation
  between these endpoints and are prestored in the CIM.

The IM and CIM stay fixed throughout the computation, and they serve
as seeds from which further representations are made.

## Misc Terms

* [Hamming Distance](https://en.wikipedia.org/wiki/Hamming_distance)

  In information theory, the Hamming distance between two strings of equal length is the number of positions at which the corresponding symbols are different. In other words, it measures the minimum number of substitutions required to change one string into the other, or the minimum number of errors that could have transformed one string into the other. In a more general context, the Hamming distance is one of several string metrics for measuring the edit distance between two sequences.

* [Independence (probability theory)](https://en.wikipedia.org/wiki/Independence_(probability_theory))

  Two events are independent, statistically independent, or stochastically independent[1] if the occurrence of one does not affect the probability of occurrence of the other (equivalently, does not affect the odds). Similarly, two random variables are independent if the realization of one does not affect the probability distribution of the other.

* [iid - Independent and identically distributed random variables](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables)

  In probability theory and statistics, a collection of random variables is independent and identically distributed if each random variable has the same probability distribution as the others and all are mutually independent.

## Refererence

* [PULP-HD](https://iis-people.ee.ethz.ch/~arahimi/papers/DAC18.pdf)
* [An Introduction to Computing in Distributed Representation with High-Dimensional Random Vectors](http://www.rctn.org/vs265/kanerva09-hyperdimensional.pdf)
